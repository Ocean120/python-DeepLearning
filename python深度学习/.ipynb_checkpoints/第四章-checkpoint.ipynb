{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 机器学习的四个分支"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 监督学习：\n",
    "给定一组样本，可以学会将输入数据映射到已知目标（有人工标注地标签）\n",
    "例：二分类问题，多分类问题，标量回归问题，序列生成，语法树预测，目标检测，图像分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 无监督学习：\n",
    "在没有目标的情况下寻找输入数据的有趣变换，目的在于数据可视化、数据压缩、数据去噪或更好地理解数据中地相关性。\n",
    "例：降维、聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 自监督学习：\n",
    "没有人工标注的标签的监督学习，标签仍然存在（因为总要有什么东西来监督学习过程），但它们是从输入数据中生成的，通常是使用启发式算法生成的。\n",
    "例：自编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.4 强化学习：\n",
    "智能体（agent）接受有关其环境的信息，并学会选择是某种奖励最大化的行动。\n",
    "例：游戏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类和回归术语表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （1）样本（sample）或输入(input)：\n",
    "进入模型的数据点\n",
    "#### （2）预测（prediction）或输出（output）：\n",
    "从模型出来的结果\n",
    "#### （3）目标（target）：\n",
    "真实值。对于外部数据源，理想情况下，模型应该能够预测出目标\n",
    "#### （4）预测误差（prediction error）或损失值（loss value）：\n",
    "模型预测与目标之间的距离\n",
    "#### （5）类别（class）：\n",
    "分类问题中供选择的一组标签\n",
    "#### （6）标签（label）：\n",
    "分类问题中类别标注的具体例子\n",
    "#### （7）真值（ground-truth）或标注（annotation）：\n",
    "数据集的所有目标，通常由人工收集\n",
    "#### （8）二分类（binary classification）：\n",
    "一种分类任务，每个输入样本都应被划分到两个互斥的类别中\n",
    "#### （9）多分类（multiclass classification）：\n",
    "一种分类任务，每个输入样本都应被划分到两个以上的类别中，比如手写数字分类\n",
    "#### （10）多标签分类（multilabel classification）：\n",
    "一种分类任务，每个输入样本都可以分配多个标签\n",
    "#### （11）标量回归（scalar regression）：\n",
    "目标是连续标量值的任务。预测房价\n",
    "#### （12）向量回归（vector regression）：\n",
    "目标是一组连续值的任务。如果对多个值（比如图像边界框的坐标）进行回归\n",
    "#### （13）小批量（mini-batch）或批量（batch）：\n",
    "模型同时处理的一小部分样本（样本数通常为8~128）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 评估机器学习模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 过拟合：\n",
    "随着训练的进行，模型再训练数据上的性能始终再提高，但在前所未见的数据上的性能则不在变化或者开始下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 泛化：\n",
    "机器学习的目标，在前所未见的数据上表现很好的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 训练集、验证集和测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 超参数：\n",
    "调节模型配置，比如选择层数或者每层大小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学习：\n",
    "在某个参数空间中寻找良好的模型配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 验证集上过拟合-信息泄露：\n",
    "每次基于模型在验证集上的性能来调节模型超参数，都会有一些关于验证数据的信息泄漏到模型中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据较少情况下，有三种经典的评估方法："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、简单的留出验证：\n",
    "留出一定比列的数据作为验证集。在剩余的数据上训练模型，然后再测试集上评估模型。并且为了防止信息泄露，不能基于测试集来调节模型，还应该保留一个验证集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_validation_samples=10000\n",
    "\n",
    "np.random.shuffle(data) # 通常需要打乱数据\n",
    "\n",
    "validation_data=data[:num_validation_samples] #定义验证集\n",
    "data=data[num_validation_samples:]\n",
    "\n",
    "training_data=data[:] #定义训练集\n",
    "\n",
    "#在训练数据上训练模型，并在验证数据上评估模型\n",
    "model=get_model() \n",
    "model.train(training_data)\n",
    "validation_score=model.evaluate(validation_data)\n",
    "\n",
    "#一旦调节好超参数，通常就在所有非测试数据上从头开始训练最终模型\n",
    "model=get_model() \n",
    "model.train(np.concatenate([training_data,validation_data]))\n",
    "test_score=model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 缺点：数据太少，无法在统计学上代表数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、K折验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=4\n",
    "num_validation_samples=len(data)//4\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_scores=[]\n",
    "for fold in range(k):\n",
    "    #选择验证数据分区\n",
    "    validation_data=data[num_validation_samples*fold:num_validation_samples*(fold+1)]\n",
    "    #使用剩余数据作为训练数据\n",
    "    traing_data=data[:num_validation_samples*fold]+data[num_validation_samples*(fold+1):]\n",
    "    \n",
    "    #创建一个全新的模型实例（未训练）\n",
    "    model=get_model()\n",
    "    model.train(traing_data)\n",
    "    \n",
    "validation_score=model.evaluate(validation_data)\n",
    "\n",
    "validation_scores.append(validation_score)\n",
    "\n",
    "#最终验证分数：K折验证分数的平均值\n",
    "validation_score=np.average(validation_scores)\n",
    "\n",
    "#在所有非测试数据上训练最终模型\n",
    "model=get_model()\n",
    "model.train(data)\n",
    "test_score=model.evaluate(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3、带有打乱数据的重复K折验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果可用的数据相对较少，而又需要尽可能精确地评估模型，那么可以选择带有大乱数据地重复K折验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 评估模型地注意事项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、数据代表性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再将数据划分为训练集和测试集之前，通常应该随机打乱数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、时间箭头"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想要根据过去预测未来，不应该随机打乱数据，因为这么做会造成时间泄露。要确保测试集中所有数据地时间都晚于训练集数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3、数据冗余\n",
    "确保训练集和验证集之间没有交集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 数据预处理、特征工程和特征学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 神经网络地数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、向量化\n",
    "数据向量化：\n",
    "无论处理什么数据（声音、图像、文本），都必须将其转化为张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、值标准化\n",
    "将数据输入网络之前，对每个特征分别做标准化，使其均值为0，标准差为1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 输入数据特征：\n",
    "取值较小：大部分值都应该在0~1范围内\n",
    "同质性：所用特征地取值都应该在大致相同的范围内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 假设x是一个形状为（samples,features）的二维矩阵\n",
    "x -= x.mean(axis=0) #均值\n",
    "x /= x.std(axis=0) #标准差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3、处理缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将缺失值设置为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将数据输入模型之前，利用你自己关于数据和机器学习算法（这里指神经网络）的知识对数据进行硬编码的变换，以改善模型的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 良好的特征可以让你用更少的资源更优雅的解决问题\n",
    "#### 良好的特征可以让你用更少的数据解决问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 过拟合与欠拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习的根本问题：优化和泛化之间的对立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 优化：\n",
    "调节模型以在训练数据上得到最佳性能（机器学习中的学习）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 泛化：\n",
    "训练好的模型在前所未见的数据上的性能好坏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 欠拟合：\n",
    "训练数据上的损失越小，测试数据上的损失也越小，此时模型就是欠拟合的，即仍有改进的空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 为了防止模型从训练数据中学到错误或者无关紧要的模式，最优解决方法是获取更多的训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 次优解决方法是调节模型允许存储的信息量，或对模型允许存储的信息加以约束"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正则化：\n",
    "如果一个网络只能记住几个模式，那么优化过程会迫使模型集中学习最重要的模式，这样更可能得到良好的泛化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 减小网络大小（最简单防止过拟合方法）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "参数数量少--欠拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数数量多--过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注：要找到合适的模型大小，一般是开始时选择相对较少的层和参数，然后逐渐增加层的大小或增加新层，直到这种增加对验证损失的影响变得很小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 添加权重正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定一些训练数据和一种网络架构，很多组权重值（即很多模型）都可以解释这些数据，简单模型比复杂模型更不容易过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 简单模型：\n",
    "参数值分布的熵更小的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 降低过拟合的方法：（权重正则化）\n",
    "#### 强制让模型权重只能取较小的值，从而限制模型的复杂度，这使得权重值的分布更加规则。\n",
    "实现方法：向网络损失函数中添加与较大权重值相关的成本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L1正则化（L1 regularization）：添加的成本与权重系数的绝对值[权重的L1范数（norm）]成正比\n",
    "##### L2正则化（L2 regularization）：添加的成本与权重系数的平方[权重的L2范数]成正比，也叫权重衰减"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 向模型添加L2权重正则化\n",
    "from keras import regularizers\n",
    "\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(16,kernel_regularizeer=regularizers.12(0.001),activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(16,kernel_regularizeer=regularizers.12(0.001),activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "# 12(0.001)的意思是该层权重矩阵的每个系数都会使网络总损失增加0.001*weight_coefficient_value\n",
    "# 这个惩罚项只在训练时添加，所以这个网络的训练损失会比测试损失大很多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 添加dropout正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在训练过程中随机将该层的一些输出特征舍弃（设置为0）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Dense(16,activation='relu',input_shape=(10000,))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(16,activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结，防止神经网络过拟合的常用方法：\n",
    "#### 1、获取更多的训练数据\n",
    "#### 2、减小网络容量\n",
    "#### 3、添加权重正则化\n",
    "#### 4、添加dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 机器学习的通用工作流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 定义问题，收集数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、你的输入数据是什么？你要预测什么？只有拥有可用的训练数据，才能学习预测某件事情。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、面对的时什么类型的问题？是二分类问题、多分类问题、标量回归问题、向量回归问题，还是多分类、多标签问题？或者其他问题，比如聚类、生成或强化学习？确定问题类型有助于你选择模型架构、损失函数等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 做出假设："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、假设输出是可以根据输入进行预测的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、假设可用数据包含足够多的信息，足以学习输入和输出之间的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 非平稳问题：无法解决的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注：\n",
    "机器学习只能用来记忆训练数据中存在的模式。智能识别出曾经见过的东西，这里存在一个假设，就是未来的规律和过去相同。但事实并非如此"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2 选择衡量成功的指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、平衡分类问题（每个类别的可能性相同）：精度和接受者操作特征曲线下面积（ROCAUC）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、类别不平衡问题：准确率和召回率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、排序问题或多标签问题：平均准确率均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4、其他（Kaggle数据科学竞赛）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3 确定评估方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、留出验证集：数据量很大时可以采用这种方法（大多数情况下使用）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、K折交叉验证：如果留出验证的样本量太少，无法保证可靠性，那么应该选择这种方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、重复的K折验证：如果可用的数据很少，同时模型评估又需要非常准确，应该使用这种方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.4 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、将数据格式化为张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、这些张量的取值通常应该缩放为较小的值，比如在[-1,1]或[0,1]区间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、如果不同的特征具有不同的取值范围（异质数据），那么应该做数据标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4、可能需要做特征工程，尤其是对于小数据问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.5 开发比基准更好的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 统计功效：开发一个小型模型，它能够打败纯随机的基准"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注：\n",
    "不一定总是能获得统计功效，如果尝试了多种合理架构之后仍然无法打败随机基准，那么原因可能是问题的答案并不在输入数据中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "记住4.5.1中的假设，但是这些假设很可能是错误的，这样就需要从头重新开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如果顺利，还需要三个关键参数来构建第一个工作模型："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、最后一层的激活：它对网络输出进行有效的限制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、损失函数：它应该匹配你要解决的问题的类型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、优化配置：你要是用哪种优化器？学习率是多少？大多数情况下，使用rmsprop及其默认的学习率是稳妥的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 问题类型--最后一层激活--损失函数\n",
    "##### 二分类问题--sigmoid--binary_crossentropy\n",
    "##### 多分类、但标签问题--softmax--categorical_crossentropy\n",
    "##### 多分类、多标签问题--sigmoid--binary_crossentropy\n",
    "##### 回归到任意值--无--mse\n",
    "##### 回归到0~1范围内的值--sigmoid--mse或binary_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.6 扩大模型规模：开发过拟合的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一旦得到了具有统计功效的模型，问题就变成了：模型是否足够强大？它是否具有足够多的层和参数来对问题进行建模？理想的模型是刚好在欠拟合和过拟合的界限上，在容量不足和容量过大的界限上。要搞清楚需要多大的模型，就必须开发一个过拟合的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）添加更多的层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）让每一层变得更大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）训练更多的轮次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要始终监控训练损失和验证损失，以及你所关心的指标的训练值和验证值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 如果模型在验证数据上的性能开始下降，那么就出现了过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.7 模型正则化与调节超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不断调节模型、训练、在验证数据上评估（这里不是测试数据）、在此调节模型，然后重复这一过程，直到模型达到最佳性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、添加dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、尝试不同的架构：增加或减少层数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、添加L1或L2正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4、尝试不同的超参数（比如每层的单元个数或优化器的学习率），以找到最佳配置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5、（可选）反复做特征工程：添加新特征或删除没有信息量的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本章小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、定义问题与要训练的数据。收集这些数据，有需要的话用标签来标注数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、选择衡量问题成功的指标。你要在验证数据上监控哪些指标？\n",
    "### 3、确定评估方法：留出验证？K折验证？你应该将哪一部分数据用于验证？\n",
    "### 4、开发第一个比基准更好地模型，即一个具有统计功效的模型\n",
    "### 5、开发过拟合的模型\n",
    "### 6、基于模型在验证数据上的性能来进行模型正则化与调节超参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
